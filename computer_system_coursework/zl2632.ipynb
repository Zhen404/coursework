{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=pyspark.SparkContext(appName='hw5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://160.39.188.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>hw5</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=hw5>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "csds-material/csds-material/input/file1 MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=sc.textFile(\"csds-material/csds-material/input/file1\")\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello World Bye World']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=lines.flatMap(lambda l:l.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello: 2\n",
      "Goodbye: 1\n",
      "World: 2\n",
      "Bye: 1\n",
      "Hadoop: 2\n"
     ]
    }
   ],
   "source": [
    "lines=sc.wholeTextFiles(\"csds-material/csds-material/input\")\n",
    "counts=lines.flatMap(lambda x:x[1].split(' ')) \\\n",
    ".map(lambda x: x.strip())\\\n",
    ".map(str) \\\n",
    ".map(lambda x: (x,1)) \\\n",
    ".reduceByKey(lambda a,b:a+b)\n",
    "output=counts.collect()\n",
    "for(word, count) in output:\n",
    "    print(\"%s: %i\" % (word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"hw5sql\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    fields=line.split(',')\n",
    "    p0=fields[0]\n",
    "    p1=fields[1]\n",
    "    p2=fields[2]\n",
    "    p3=float(fields[3])\n",
    "    p4=fields[4]\n",
    "    return (p0,p1,p2,p3,p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=spark.sparkContext\n",
    "lines=sc.textFile(\"csds-material/csds-material/hive/purchases.txt\")\n",
    "\n",
    "# Each line is converted to a tuple\n",
    "purchase=lines.map(parse_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "field1=StructField('timestamp',StringType(),True)\n",
    "field2=StructField('location',StringType(),True)\n",
    "field3=StructField('category',StringType(),True)\n",
    "field4=StructField('price',FloatType(),True)\n",
    "field5=StructField('card',StringType(),True)\n",
    "\n",
    "fields=[field1,field2,field3,field4,field5]\n",
    "schema=StructType(fields)\n",
    "\n",
    "schemaPurchase=spark.createDataFrame(purchase,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaPurchase.createOrReplaceTempView(\"purchase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What is the average price of the products that were purchased via Mastercard?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(price)|\n",
      "+-----------------+\n",
      "|275.0677317417774|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT AVG(price) FROM purchase WHERE card='MasterCard'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "| timestamp|       sum(price)|\n",
      "+----------+-----------------+\n",
      "|2012-03-17|2384.480026245117|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT timestamp, sum(price) FROM \\\n",
    "(SELECT CAST(timestamp AS DATE), price FROM purchase) \\\n",
    "group by timestamp order by sum(price) desc limit 1\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What is the minimum value of a product under the Computers category?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(price)|\n",
      "+----------+\n",
      "|      0.38|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT min(price) FROM purchase WHERE category='Computers'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How many distinct categories of products are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|distinct_category_number|\n",
      "+------------------------+\n",
      "|                      18|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(distinct(category)) as distinct_category_number FROM purchase\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Which store location had the lowest total sales?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|lowest_sale_location|      total_price|\n",
      "+--------------------+-----------------+\n",
      "|               Plano|784.9599838256836|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT location as lowest_sale_location,sum(price) as total_price FROM purchase \\\n",
    "GROUP BY location ORDER BY total_price limit 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2012-07-20 09:59:00', 'Corpus Christi', 'CDs', 327.91, 'Cash'),\n",
       " ('2012-03-11 17:29:00', 'Durham', 'Books', 115.09, 'Discover'),\n",
       " ('2012-07-31 11:43:00', 'Rochester', 'Toys', 332.07, 'MasterCard'),\n",
       " ('2012-06-18 14:47:00', 'Garland', 'Computers', 31.99, 'Visa'),\n",
       " ('2012-03-27 11:40:00', 'Tulsa', 'CDs', 452.18, 'Discover')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaseDF=purchase.toDF(['timestamp','location','category','price','card'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+---------+------+----------+\n",
      "|          timestamp|      location| category| price|      card|\n",
      "+-------------------+--------------+---------+------+----------+\n",
      "|2012-07-20 09:59:00|Corpus Christi|      CDs|327.91|      Cash|\n",
      "|2012-03-11 17:29:00|        Durham|    Books|115.09|  Discover|\n",
      "|2012-07-31 11:43:00|     Rochester|     Toys|332.07|MasterCard|\n",
      "|2012-06-18 14:47:00|       Garland|Computers| 31.99|      Visa|\n",
      "|2012-03-27 11:40:00|         Tulsa|      CDs|452.18|  Discover|\n",
      "+-------------------+--------------+---------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchaseDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What is the average price of the products that were purchased via Mastercard?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(price)|\n",
      "+-----------------+\n",
      "|275.0677319587629|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchaseDF.filter(purchaseDF.card=='MasterCard').agg(avg(col('price'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Which date recorded the highest total sales?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(sales_date=datetime.date(2012, 3, 17), sum(price)=2384.48)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaseDF.withColumn('sales_date',purchaseDF['timestamp'].cast(TimestampType()).cast(DateType()))\\\n",
    ".select('sales_date','price').groupBy('sales_date').agg({'price': 'sum'}).orderBy(desc('SUM(price)')).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What is the minimum value of a product under the Computers category?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(price)|\n",
      "+----------+\n",
      "|      0.38|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchaseDF.filter(purchaseDF.category=='Computers').agg(min(col('price'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How many distinct categories of products are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaseDF.select('category').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Which store location had the lowest total sales?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(location='Plano', sum(price)=784.96)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaseDF.select('location','price').groupBy('location').agg({'price': 'sum'}).orderBy('SUM(price)').first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
